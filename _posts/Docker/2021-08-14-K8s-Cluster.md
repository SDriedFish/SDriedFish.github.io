---
layout: post
title: k8s-集群操作
categories: Docker
tags: Docker
keywords: k8s-集群操作
date: 2021-08-14
---
# 部署Tomcat集群

**页面集群部署tomcat**

![image-20210901215354505](/assets/img/Docker/K8s-Cluster/image-20210901215354505.png)

**怎么访问 tomcat**  `{nodeip}:32494` 

![image-20210901214835589](/assets/img/Docker/K8s-Cluster/image-20210901214835589.png)

**k8s master 分发命令道node节点  负责镜像拉取和容器部署**

![image-20210901214957278](/assets/img/Docker/K8s-Cluster/image-20210901214957278.png)

**k8s 轮询重新创建杀掉的容器**

`docker rm -f 86552cea5d69` 移除容器后会自动创建

# 脚本部署Tomcat

**Deployment流程**

- 部署是指Kubernetes向Node节点发送指令，创建容器的过程
- Kubernetes支持yml格式的部署脚本
- kubectl create -f 部署yml文件 #创建部署

**样例**

```yaml
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  name: tomcat-deploy
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: tomcat-cluster
    spec:
      volumes:
      - name: web-app
        hostPath:
          path: /mnt
      containers:
      - name: tomcat-cluster
        image: tomcat:latest
        resources:
          requests:
            cpu: 0.5
            memory: 200Mi
          limits:
            cpu: 1
            memory: 512Mi
        ports:
        - containerPort: 8080
        volumeMounts:
        - name: web-app
          mountPath: /usr/local/tomcat/webapps
```

**与部署相关常用命令**

- kubectl create -f 部署yml文件 #创建部署

- kubectl apply -f 部署yml文件 #更新部署配置

- kubectl get pod [-o wide] #查看已部署pod

- kubectl describe pod pod名称 #查看Pod详细信息

- kubectl logs [-f] pod名称 #查看pod输出日志  -f 是否实时更新

  ![image-20210901221423844](/assets/img/Docker/K8s-Cluster/image-20210901221423844.png)

  ![image-20210901221504566](/assets/img/Docker/K8s-Cluster/image-20210901221504566.png)

**外部访问Tomcat集群**

Service服务用于对外暴露应用  负载均衡

<img src="/assets/img/Docker/K8s-Cluster/image-20210901221157662.png" alt="image-20210901221157662" style="zoom:50%;" />

```yaml
apiVersion: v1
kind: Service
metadata:
  name: tomcat-service
  labels:
    app: tomcat-service
spec:

#  type: NodePort

  selector:
    app: tomcat-cluster  #部署时所设的label
  ports:

  - port: 8000
    targetPort: 8080
#    nodePort: 32500    
```

![image-20210901222952003](/assets/img/Docker/K8s-Cluster/image-20210901222952003.png)

部署完服务后可以通过`{nodeip}:32500` 访问tomcat

**集群文件共享**

基于NFS文件集群共享

- NFS,是由SUN公司研制的文件传输协议

- NFS主要是采用远程过程调用RPC机制实现文件传输

- yum install -y nfs-utils rpcbind 

  ![image-20210902221026603](/assets/img/Docker/K8s-Cluster/image-20210902221026603.png)

  可以将node3看成文件共享服务器，保存了这个集群中所有要共享的文件数据，通过目录挂载，进行远程的文件目录映射。



```shell
# 安装nfs rpcbind
yum install -y nfs-utils rpcbind 

#  创建共享文件夹
mkdir -p /usr/local/data/www-data && cd /usr/local/data/www-data

vim /etc/exports
# 编辑内容
/usr/local/data/www-data 10.0.0.131/24(rw,sync) # rw表示可读可写，sync表示同步写入

# 启动nfs服务、设置开机启动
systemctl start nfs.service
systemctl enable nfs.service

# 启动rpc绑定服务、设置开机启动
systemctl start rpcbind.service
systemctl enable rpcbind.service

exportfs  #查看配置是否生效
/usr/local/data/www-data
		192.168.10.71/24
		
```

在两台node上进行以下设置

```shell
# 将 master 上的/usr/local/data/www-data，挂载到本机的/mnt下
mount node11:/usr/local/data/www-data /mnt
```

![image-20210902222420583](/assets/img/Docker/K8s-Cluster/image-20210902222420583.png)

![image-20210902222339556](/assets/img/Docker/K8s-Cluster/image-20210902222339556.png)

修改tomcat-deploy.yml文件

```yaml
spec:
  volumes:
  - name: web-app
    hostPath:
      path: /mnt
  containers:
  - name: tomcat-cluster
    image: tomcat:latest
    ports:
    - containerPort: 8080
    volumeMounts:
    - name: web-app
      mountPath: /usr/local/tomcat/webapps
```


**利用Rinetd实现Service负载均衡**

- Rinetd是Linux操作系统中为重定向传输控制协议工具

- 可将源IP端口数据转发至目标IP端口

- 在Kubernetes中用于将service服务对外暴露

  

  在`/usr/local/data/www-data` 创建index.jsp

```jsp
# index.jsp
当前服务器ip：<%=request.getLocalAddr()%>
```

多次请求`curl 10.110.220.98:8000/test`，你看，请求被随机发送到两台节点上了，k8s帮我们做了负载均衡

![image-20210902223634632](/assets/img/Docker/K8s-Cluster/image-20210902223634632.png)

`10.110.220.98:8000` 在**外部的浏览器是无法访问的**  可以使用 Linux 中的端口转发工具：Rinetd

**安装Rinetd**

```shell
wget https://boutell.com/rinetd/http/rinetd.tar.gz # 这个已经访问不到了，需要自行下载离线包
tar -xvf rinetd.tar.gz
cd rinetd
sed -i 's/65536/65535/g' rinetd.c
mkdir -p /usr/man/  # rinetd的要求目录，需要手动创建
yum install -y gcc  # 没有gcc的话安装一下
make && make install

vi /etc/rinetd.conf

# 配置文件格式很简单：[Source Address] [Source Port] [Destination Address] [Destination Port]

# 0.0.0.0表示允许所有ip发送请求，8000表示master对外开放8000端口
# 每当 master 的 8000 端口接收到请求后，都转发到内部的 10.110.220.98:8000

rinetd -c /etc/rinetd.conf  #启动加载
netstat -tanulp|grep rinetd # 检验端口转发程序
```

![image-20210902225034669](/assets/img/Docker/K8s-Cluster/image-20210902225034669.png)

**集群配置调整与资源限定**

- 更新集群配置

- kubectl apply -f yml文件路径

- 删除部署(Deployment)|服务(Service)

- kubectl delete deployment|service 部署|服务名称

  

  资源进行限定

  CPU 的单位是核，可以是小数

```yaml
containers:
      - name: tomcat-cluster
        image: tomcat:latest
        resources:
          requests:
            cpu: 1 
            memory: 500Mi
          limits: 
            cpu: 2
            memory: 1024Mi
```

![image-20210902225703153](/assets/img/Docker/K8s-Cluster/image-20210902225703153.png)

# 项目拓扑

![image-20210903224621308](/assets/img/Docker/K8s-Cluster/image-20210903224621308.png)

步骤

```shell
#在node11节点执行
# nfs 挂载共享目录
vim /etc/exports
# 添加内容
/home/java/k8s/beiqin/dist 192.168.10.71/24(rw,sync)
/home/java/k8s/beiqin/sql 192.168.10.71/24(rw,sync)
# 重启nfs.service
systemctl restart nfs.service
systemctl restart rpcbind.service
# 查询挂载是否生效
exportfs


# 在node12节点执行
# 创建目录 挂载在node11共享目录
mkdir -p /usr/local/beiqin-dist /usr/local/beiqin-sql
mount node11:/home/java/k8s/beiqin/dist /usr/local/beiqin-dist
mount node11:/home/java/k8s/beiqin/sql /usr/local/beiqin-sql
# 查看挂载是否成功
ls /usr/local/beiqin-dist
```

`beiqin-db-deploy.yml`

```yaml
apiVersion: apps/v1beta1
kind: Deployment
metadata:
  name: beiqin-db-deploy
spec:
  replicas: 1
  template:
    metadata:
      labels:
        app: beiqin-db-deploy
    spec:
      volumes:
      - name: beiqin-db-volume
        hostPath:
          path: /usr/local/beiqin-sql
      containers:
      - name: beiqin-db-deploy
        image: mysql:5.7
        ports:
        - containerPort: 3306
        env:
        - name: MYSQL_ROOT_PASSWORD
          value: "root"
        volumeMounts:
        - name: beiqin-db-volume
          mountPath: /docker-entrypoint-initdb.d
```

`kubectl create -f beiqin-db-deploy.yml` 部署mysql pod

**mysql部署成功**

![image-20210903231426621](/assets/img/Docker/K8s-Cluster/image-20210903231426621.png)

`beiqin-db-service.yml`

 ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: beiqin-db-service
      labels: 
        app: beiqin-db-service
    spec:
      selector:
        app: beiqin-db-deploy
      ports:
    
      - port: 3310
        targetPort: 3306
 ```

​    `kubectl create -f beiqin-db-service.yml` 部署mysql服务

`beiqin-app-deploy.yml`

```
kind: Deployment
metadata:
  name: beiqin-app-deploy
spec:
  replicas: 2
  template:
    metadata:
      labels:
        app: beiqin-app-deploy
    spec:
      volumes:
      - name : beqin-app-volume
        hostPath:
          path: /usr/local/beiqin-dist
      containers:
      - name: beiqin-app-deploy
        image: openjdk:8u222-jre
        command: ["/bin/sh"]
        args: ["-c","cd /usr/local/beiqin-dist;java -jar beiqin-app.jar"]
        volumeMounts:
        - name: beqin-app-volume
          mountPath: /usr/local/beiqin-dist
```

`kubectl create -f beiqin-app-deploy.yml` 部署app pod

![image-20210903234800094](/assets/img/Docker/K8s-Cluster/image-20210903234800094.png)

   ```yaml
    apiVersion: v1
    kind: Service
    metadata:
      name: beiqin-app-service
      labels: 
        app: beiqin-app-service
    spec:
      selector:
        app: beiqin-app-deploy
      ports:
    
      - port: 80
        targetPort: 80
   ```

​    `kubectl create -f beiqin-app-service.yml` 部署app服务

端口转发

```
vi /etc/rinetd.conf
rinetd -c /etc/rinetd.conf  #启动加载
```

![image-20210904000056883](/assets/img/Docker/K8s-Cluster/image-20210904000056883.png)
